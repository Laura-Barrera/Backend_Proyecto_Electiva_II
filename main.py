# -*- coding: utf-8 -*-
"""Copia de Base modelo

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rqotY2o7zGHvOtza7ptMKph7DEJB94tY
"""

import tensorflow as tf

import os
from google.cloud import dialogflow_v2 as dialogflow
import json
import pandas as pd
import numpy as np
import uvicorn
import threading
import nest_asyncio

from fastapi import FastAPI, File, UploadFile, Form
from fastapi.responses import JSONResponse
from typing import Optional
import shutil
import uuid
import os

# Configuraciones generales
import warnings
warnings.filterwarnings('ignore')

from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.efficientnet import preprocess_input

from huggingface_hub import hf_hub_download
from tensorflow.keras.layers import Layer
import tensorflow.keras.backend as K


"""Urilizar modelo desde Huggong Face

https://huggingface.co/liriope/PlantDiseaseDetection
"""

# Descargar el modelo
model_path = hf_hub_download(repo_id="liriope/PlantDiseaseDetection", filename="plant_disease_efficientnetb4.h5")

# Cargar el modelo completo incluyendo la capa personalizada
modelo_cnn = tf.keras.models.load_model(model_path)

modelo_cnn.summary()

image_path = "AppleCedarRust1.JPG"

img = image.load_img(image_path, target_size=(380, 380))  # El tamaño debe coincidir con el tamaño de entrada del modelo

# Convertir la imagen a un array de NumPy
img_array = image.img_to_array(img)

# Añadir una dimensión extra para el batch (modelo espera un batch de imágenes, no solo una)
img_array = np.expand_dims(img_array, axis=0)

# Preprocesar la imagen para que esté en el formato correcto para EfficientNetB4
img_array = preprocess_input(img_array)

# Realizar la predicción
predictions = modelo_cnn.predict(img_array)

predictions

diccionario_es = {
    0: 'Manzana Sarna del manzano',
    1: 'Manzana Podredumbre negra',
    2: 'Manzana Oxido del cedro y manzano',
    3: 'Manzana sana',
    4: 'Arándano sano',
    5: 'Cereza (incluyendo agria) mildiú polvoroso',
   6: 'Cereza (incluyendo agria) sana',
   7: 'Maíz Mancha foliar de Cercospora Mancha gris de la hoja',
   8: 'Maíz Roya común',
   9: 'Maíz Tizón foliar del norte',
   10: 'Maíz sano',
   11: 'Uva Podredumbre negra',
   12: 'Uva Esca (Yesca)',
   13: 'Uva Tizón de la hoja (Mancha foliar de Isariopsis)',
   14: 'Uva sana',
   15: 'Naranja Huanglongbing (Greening de los cítricos)',
   16: 'Melocotón Mancha bacteriana',
   17: 'Melocotón sano',
   18: 'Pimiento Mancha bacteriana',
   19: 'Pimiento sano',
   20: 'Papa Tizón temprano',
   21: 'Papa Tizón tardío',
   22: 'Papa sana',
   23: 'Frambuesa sana',
   24: 'Soja sana',
   25: 'Calabaza Oídio',
   26: 'Fresa Quemadura de la hoja',
   27: 'Fresa sana',
   28: 'Tomate Mancha bacteriana',
   29: 'Tomate Tizón temprano',
   30: 'Tomate Tizón tardío',
   31: 'Tomate Moho de la hoja',
   32: 'Tomate Mancha foliar de Septoria',
   33: 'Tomate Araña roja Ácaro de dos puntos',
   34: 'Tomate Mancha objetivo',
   35: 'Tomate Virus del enrollamiento de la hoja amarilla del tomate',
   36: 'Tomate Virus del mosaico del tomate',
   37: 'Tomate sano'
}

predicted_class_index = np.argmax(predictions)

# Obtener el nombre de la clase (enfermedad) correspondiente
predicted_class_name = diccionario_es[predicted_class_index]

print(f"La enfermedad predicha es: {predicted_class_name}")

"""## Dialog Flow"""

def AnalizarEnfermedadHoja(path_imagen):
    try:
        img = image.load_img(path_imagen, target_size=(380, 380))
        img_array = image.img_to_array(img)
        img_array = np.expand_dims(img_array, axis=0)
        img_array = preprocess_input(img_array)

        predictions = modelo_cnn.predict(img_array)
        predicted_index = np.argmax(predictions)
        return diccionario_es.get(predicted_index, "Desconocido")
    except Exception as e:
        return f"Error al procesar la imagen: {str(e)}"

import numpy as np
import requests
from io import BytesIO
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.efficientnet import preprocess_input

def AnalizarEnfermedadHoja(path_imagen):
    try:
        # Detectar si es una URL o una ruta local
        if path_imagen.startswith("http://") or path_imagen.startswith("https://"):
            response = requests.get(path_imagen)
            if response.status_code != 200:
                return "No se pudo acceder a la imagen desde la URL"
            img = image.load_img(BytesIO(response.content), target_size=(380, 380))
        else:
            img = image.load_img(path_imagen, target_size=(380, 380))

        img_array = image.img_to_array(img)
        img_array = np.expand_dims(img_array, axis=0)
        img_array = preprocess_input(img_array)

        predictions = modelo_cnn.predict(img_array)
        predicted_index = np.argmax(predictions)
        return diccionario_es.get(predicted_index, "Desconocido")

    except Exception as e:
        return f"Error al procesar la imagen: {str(e)}"

AnalizarEnfermedadHoja("AppleCedarRust3.JPG")

AnalizarEnfermedadHoja("https://cdn.britannica.com/89/126689-004-D622CD2F/Potato-leaf-blight.jpg?w=400&h=300&c=crop")

"""### credenciales"""

# Cargar las credenciales desde el JSON a las variables de entorno
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "asistenteuptcadne-458017-c07d554b0041.json"
with open("asistenteuptcadne-458017-c07d554b0041.json","r") as f:
  datos = json.load(f)

print("ProjectID: ", datos['project_id'])
print("Client Email: ", datos['client_email'])
print(os.environ["GOOGLE_APPLICATION_CREDENTIALS"])

# Probar la conexión
try:
  session_client = dialogflow.SessionsClient()
  print("Conexión exitosa")
except Exception as e:
  print(f"Error de conexión: {e}")

# Información del proyecto
project_id = "asistenteuptcadne-458017"
language_code = "es"
session_id = "session1"

# Función conversacional completa
def detec_intent_texts_full(project_id, session_id, text, language_code):
  session_client = dialogflow.SessionsClient()
  session = session_client.session_path(project_id, session_id)

  text_input = dialogflow.TextInput(text=text, language_code=language_code)
  query_input = dialogflow.QueryInput(text=text_input)

  response = session_client.detect_intent(
      request={"session" : session, "query_input": query_input}
  )

  # Extraer información importante:
  fulfillment_text = response.query_result.fulfillment_text # texto que retorna el agente
  intent = response.query_result.intent.display_name # intención que retorna el agente
  confianza = response.query_result.intent_detection_confidence # confianza del agente al clasificar esa intención 0 - 1
  parametros = dict(response.query_result.parameters) # ... parámetros de la intención

  # Crear un diccionario con la información
  return {
      "respuesta": fulfillment_text,
      "intencion": intent,
      "confianza": confianza,
      "parametros": dict(parametros)
  }

"""# **Uso dialogflow**"""

data = detec_intent_texts_full(project_id, session_id, "chao", language_code)
print("ADNEUPTC dice: ", data['respuesta'])
print("\nIntención: ", data['intencion'])
print("\nConfianza: ", data['confianza'])
print("\nParámetros: ", data['parametros'])

"""¿esta planta esta enferma? https://cdn.britannica.com/89/126689-004-D622CD2F/Potato-leaf-blight.jpg?w=400&h=300&c=crop"""


"""# **FastAPI**"""


from fastapi import FastAPI, File, Form, UploadFile
from fastapi.responses import JSONResponse
from typing import Optional
import uuid
import os
import shutil
from pyngrok import ngrok
import uvicorn
import nest_asyncio
import re

# Requerido si estás en Colab o Jupyter
nest_asyncio.apply()

def extraer_url(texto):
    urls = re.findall(r'(https?://\S+)', texto)
    print(urls)
    return urls[0] if urls else None
from fastapi.middleware.cors import CORSMiddleware
app = FastAPI(title="backend-api")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Puedes especificar tu URL de frontend en lugar de "*"
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def home():
    return JSONResponse(content="API del backend del proyecto integrador")

@app.post("/test")
async def test(
    mensaje: str = Form(...),
    imagen: Optional[UploadFile] = File(None)
):
    if imagen:
        extension = imagen.filename.split('.')[-1]
        filename = f"{uuid.uuid4()}.{extension}"
        imagen_path = os.path.join(".", filename)

        try:
            with open(imagen_path, "wb") as buffer:
                shutil.copyfileobj(imagen.file, buffer)
            return JSONResponse(content={"status": 200, "filename": filename})
        except Exception as e:
            return JSONResponse(content={"status": 500, "error": str(e)}, status_code=500)

    return JSONResponse(content={"status": 400, "error": "No se proporcionó imagen"}, status_code=400)



@app.post("/conversar")
async def conversar(
    mensaje: str = Form(...),
    imagen: Optional[UploadFile] = File(None)):

    resultado = detec_intent_texts_full(project_id, session_id, mensaje, language_code)

    imagen_path = None

    # Caso 1: imagen cargada directamente
    if imagen:
        extension = imagen.filename.split('.')[-1]
        filename = f"{uuid.uuid4()}.{extension}"
        imagen_path = os.path.join("uploads", filename)
        os.makedirs("uploads", exist_ok=True)

        with open(imagen_path, "wb") as buffer:
            shutil.copyfileobj(imagen.file, buffer)

        resultado["imagen_guardada"] = imagen_path
        resultado["prediccion"] = AnalizarEnfermedadHoja(imagen_path)

    # Caso 2: se envió una URL en el mensaje
    else:
        url_detectada = extraer_url(mensaje)
        if url_detectada:
            resultado["url_detectada"] = url_detectada
            resultado["prediccion"] = AnalizarEnfermedadHoja(url_detectada)

    return JSONResponse(content=resultado)


if __name__ == "__main__":
    port = int(os.environ.get("PORT", 10000))  # Render define el puerto con la variable PORT
    uvicorn.run(app, host="0.0.0.0", port=port)